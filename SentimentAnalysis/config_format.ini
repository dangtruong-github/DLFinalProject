[general]
containing_folder=MachineTranslation
test=0

[train]
model=NOATTENTION
learning_rate=2e-5
weight_decay=1e-4
class_weight=0
batch_size=32
batch_size_test=2
epoch=50
epoch_test=2
batch_print=40
finetune_folder=vinai-translate-en2vi

[encoder_no_attention]
embeddings_size=10
hidden_size=10
num_layers=4
dropout_rate=0.6

[transformer]
d_model=512
num_layers=4

[preprocessing]
vn_max_indices=512
en_max_indices=512
max_token_length=128
filename_train=train
filename_val=tst2012
filename_test=tst2013
dir_to_save_hf_data=hf_folder
filename_to_save_noise=noise_indices.npy
train_sample_used=10000
filename_to_save=indices.npy
filename_dict=dict.json
tokenizer_folder=google-t5-small