{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP0dW1ht3K0YsFJbvezPTyr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"4c5408ad02fd45b88a1c818894548735":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_95a78c2e8cdb40719139d6ee0655454e","IPY_MODEL_48253e76c8f64e6b874a7a8c805db848","IPY_MODEL_e222a1a3284c4f21bcec22b7e5cd02a2"],"layout":"IPY_MODEL_1cbe3659c6db417ea614afbb1395e859"}},"95a78c2e8cdb40719139d6ee0655454e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a35f31822dea45e0b53d31c326e3df46","placeholder":"​","style":"IPY_MODEL_d9a0d8829c24456cbea22666ecce5317","value":"Map: 100%"}},"48253e76c8f64e6b874a7a8c805db848":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_57ef4ad98bd744f49bad00387e175972","max":1821,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1dee8508fb174cd38a6153a2d28b8ffd","value":1821}},"e222a1a3284c4f21bcec22b7e5cd02a2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_21928c6f6ca947beabd34d1e0bd7a33d","placeholder":"​","style":"IPY_MODEL_13722251c6cd4dbdbd496c248fba98db","value":" 1821/1821 [00:00&lt;00:00, 2835.25 examples/s]"}},"1cbe3659c6db417ea614afbb1395e859":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a35f31822dea45e0b53d31c326e3df46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9a0d8829c24456cbea22666ecce5317":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"57ef4ad98bd744f49bad00387e175972":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1dee8508fb174cd38a6153a2d28b8ffd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"21928c6f6ca947beabd34d1e0bd7a33d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13722251c6cd4dbdbd496c248fba98db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Import necessary libraries\n","\n"],"metadata":{"id":"J1C0PJIAiA4m"}},{"cell_type":"markdown","source":["## Drive + pip install"],"metadata":{"id":"ky4v24_4rdLc"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xyYA8wF_lr7G","executionInfo":{"status":"ok","timestamp":1719149808462,"user_tz":-420,"elapsed":10178,"user":{"displayName":"Vietnamese History Project","userId":"05323965769577706583"}},"outputId":"a3ef8bc1-e43b-4695-8304-761777a130e6"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd \"/content/drive/MyDrive/ML/SentimentAnalysis\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hFz90jAAmQbb","executionInfo":{"status":"ok","timestamp":1719149823433,"user_tz":-420,"elapsed":377,"user":{"displayName":"Vietnamese History Project","userId":"05323965769577706583"}},"outputId":"90a80e14-290a-4184-a4f9-e8d37615a092"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ML/SentimentAnalysis\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"FrY-8AlguVrb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719149838828,"user_tz":-420,"elapsed":15056,"user":{"displayName":"Vietnamese History Project","userId":"05323965769577706583"}},"outputId":"8a0d90f9-6eea-43dd-a52f-2a0d399015c9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting evaluate\n","  Downloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n","Collecting pyarrow>=15.0.0 (from datasets)\n","  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n","Collecting requests>=2.32.2 (from datasets)\n","  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n","Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.6.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, requests, pyarrow, dill, multiprocess, datasets, evaluate\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.31.0\n","    Uninstalling requests-2.31.0:\n","      Successfully uninstalled requests-2.31.0\n","  Attempting uninstall: pyarrow\n","    Found existing installation: pyarrow 14.0.2\n","    Uninstalling pyarrow-14.0.2:\n","      Successfully uninstalled pyarrow-14.0.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n","google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n","ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-2.20.0 dill-0.3.8 evaluate-0.4.2 multiprocess-0.70.16 pyarrow-16.1.0 requests-2.32.3 xxhash-3.4.1\n"]}],"source":["!pip install datasets evaluate"]},{"cell_type":"markdown","source":["## Other libraries"],"metadata":{"id":"DP8zz5StrfES"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn.functional as F\n","\n","import math\n","import os\n","import numpy as np"],"metadata":{"id":"zdVMMxQtkybv","executionInfo":{"status":"ok","timestamp":1719149844067,"user_tz":-420,"elapsed":5250,"user":{"displayName":"Vietnamese History Project","userId":"05323965769577706583"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\""],"metadata":{"id":"trvZjeWVlapG","executionInfo":{"status":"ok","timestamp":1719149844069,"user_tz":-420,"elapsed":11,"user":{"displayName":"Vietnamese History Project","userId":"05323965769577706583"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["# Config"],"metadata":{"id":"A8f26D0fiEox"}},{"cell_type":"code","source":["max_token_length= 128\n","d_model = 512\n","num_layer = 6\n","factor = 4\n","n_head = 8\n","\n","learning_rate = 2e-5\n","weight_decay = 1e-3\n","\n","batch_size = 32\n","dropout = 0.1\n","\n","d_ff = 2048"],"metadata":{"id":"kBVENjfj1E7C","executionInfo":{"status":"ok","timestamp":1719149844070,"user_tz":-420,"elapsed":10,"user":{"displayName":"Vietnamese History Project","userId":"05323965769577706583"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["# Data preprocessing"],"metadata":{"id":"oo8iYdl0iG-z"}},{"cell_type":"code","source":["from datasets import load_dataset\n","dataset = load_dataset('glue', 'sst2')"],"metadata":{"id":"b0LR1tvp1F4J","executionInfo":{"status":"ok","timestamp":1719152674738,"user_tz":-420,"elapsed":1583,"user":{"displayName":"Vietnamese History Project","userId":"05323965769577706583"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"],"metadata":{"id":"WuQkzzLa125z","executionInfo":{"status":"ok","timestamp":1719152674739,"user_tz":-420,"elapsed":20,"user":{"displayName":"Vietnamese History Project","userId":"05323965769577706583"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["def preprocess_function(examples):\n","    return tokenizer(examples[\"sentence\"], padding='max_length', truncation=True, max_length=max_token_length)"],"metadata":{"id":"enObtVSI14vd","executionInfo":{"status":"ok","timestamp":1719152674739,"user_tz":-420,"elapsed":19,"user":{"displayName":"Vietnamese History Project","userId":"05323965769577706583"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["tokenized_train = dataset[\"train\"].map(preprocess_function, batched=True)\n","tokenized_val = dataset[\"validation\"].map(preprocess_function, batched=True)\n","tokenized_test = dataset[\"test\"].map(preprocess_function, batched=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0,"referenced_widgets":["4c5408ad02fd45b88a1c818894548735","95a78c2e8cdb40719139d6ee0655454e","48253e76c8f64e6b874a7a8c805db848","e222a1a3284c4f21bcec22b7e5cd02a2","1cbe3659c6db417ea614afbb1395e859","a35f31822dea45e0b53d31c326e3df46","d9a0d8829c24456cbea22666ecce5317","57ef4ad98bd744f49bad00387e175972","1dee8508fb174cd38a6153a2d28b8ffd","21928c6f6ca947beabd34d1e0bd7a33d","13722251c6cd4dbdbd496c248fba98db"]},"id":"K_wPAgfb15gS","executionInfo":{"status":"ok","timestamp":1719152675279,"user_tz":-420,"elapsed":558,"user":{"displayName":"Vietnamese History Project","userId":"05323965769577706583"}},"outputId":"9f094655-99d5-4820-8085-93719f1f716f"},"execution_count":59,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1821 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c5408ad02fd45b88a1c818894548735"}},"metadata":{}}]},{"cell_type":"code","source":["tmp_data = np.array(tokenized_train[\"input_ids\"])\n","vocab_size = np.max(tmp_data) + 1\n","tmp_data = None"],"metadata":{"id":"Y8NcZvcTrUjA","executionInfo":{"status":"ok","timestamp":1719152683689,"user_tz":-420,"elapsed":7997,"user":{"displayName":"Vietnamese History Project","userId":"05323965769577706583"}}},"execution_count":60,"outputs":[]},{"cell_type":"code","source":["tmp_data = np.array(tokenized_train[\"label\"])\n","num_classes = np.max(tmp_data) + 1\n","tmp_data = None"],"metadata":{"id":"A2xr0wZAwaDp","executionInfo":{"status":"ok","timestamp":1719152683690,"user_tz":-420,"elapsed":37,"user":{"displayName":"Vietnamese History Project","userId":"05323965769577706583"}}},"execution_count":61,"outputs":[]},{"cell_type":"code","source":["class CustomDataset(Dataset):\n","    def __init__(self, data):\n","        self.data = data[\"input_ids\"]\n","        self.label = data[\"label\"]\n","        self.length = len(self.label)\n","\n","    def __len__(self):\n","        return self.length\n","\n","    def __getitem__(self, index):\n","        torch_data = torch.tensor(self.data[index], dtype=torch.int64)\n","        torch_label = torch.tensor(self.label[index], dtype=torch.int64)\n","\n","        return (torch_data, torch_label)"],"metadata":{"id":"8amSIGlAnnJr","executionInfo":{"status":"ok","timestamp":1719152683691,"user_tz":-420,"elapsed":35,"user":{"displayName":"Vietnamese History Project","userId":"05323965769577706583"}}},"execution_count":62,"outputs":[]},{"cell_type":"code","source":["torch_dataset_train = CustomDataset(tokenized_train)\n","torch_dataset_val = CustomDataset(tokenized_val)\n","torch_dataset_test = CustomDataset(tokenized_test)"],"metadata":{"id":"GZ3xxY8roFHE","executionInfo":{"status":"ok","timestamp":1719152688064,"user_tz":-420,"elapsed":4407,"user":{"displayName":"Vietnamese History Project","userId":"05323965769577706583"}}},"execution_count":63,"outputs":[]},{"cell_type":"code","source":["torch_train_loader = DataLoader(torch_dataset_train, batch_size=batch_size, shuffle=True)\n","torch_val_loader = DataLoader(torch_dataset_val, batch_size=batch_size, shuffle=True)\n","torch_test_loader = DataLoader(torch_dataset_test, batch_size=batch_size, shuffle=True)"],"metadata":{"id":"w9qQwBqcoNxF","executionInfo":{"status":"ok","timestamp":1719152688610,"user_tz":-420,"elapsed":575,"user":{"displayName":"Vietnamese History Project","userId":"05323965769577706583"}}},"execution_count":64,"outputs":[]},{"cell_type":"markdown","source":["# Model"],"metadata":{"id":"GzzKd2wSiOSd"}},{"cell_type":"code","source":["class MultiHeadAttention(nn.Module):\n","    def __init__(self, d_model, n_head):\n","        super(MultiHeadAttention, self).__init__()\n","        assert d_model % n_head == 0, \"d_model must be divisible by n_head\"\n","\n","        self.d_model = d_model\n","        self.n_head = n_head\n","        self.d_k = d_model // n_head\n","\n","        self.W_q = nn.Linear(d_model, d_model)\n","        self.W_k = nn.Linear(d_model, d_model)\n","        self.W_v = nn.Linear(d_model, d_model)\n","        self.W_o = nn.Linear(d_model, d_model)\n","\n","    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n","        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n","\n","        if mask is not None:\n","            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n","\n","        attn_probs = torch.softmax(attn_scores, dim=-1)\n","        output = torch.matmul(attn_probs, V)\n","        return output\n","\n","    def split_heads(self, x):\n","        batch_size, seq_length, d_model = x.size()\n","        return x.view(batch_size, seq_length, self.n_head, self.d_k).transpose(1, 2)\n","\n","    def combine_heads(self, x):\n","        batch_size, _, seq_length, d_k = x.size()\n","        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n","\n","    def forward(self, Q, K, V, mask=None):\n","        Q = self.split_heads(self.W_q(Q))\n","        K = self.split_heads(self.W_k(K))\n","        V = self.split_heads(self.W_v(V))\n","\n","        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n","\n","        output = self.W_o(self.combine_heads(attn_output))\n","        return output"],"metadata":{"id":"9HjMAEP7kaWQ","executionInfo":{"status":"ok","timestamp":1719149886009,"user_tz":-420,"elapsed":47,"user":{"displayName":"Vietnamese History Project","userId":"05323965769577706583"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["class PositionWiseFeedForward(nn.Module):\n","    def __init__(self, d_model, d_ff):\n","        super(PositionWiseFeedForward, self).__init__()\n","        self.fc1 = nn.Linear(d_model, d_ff)\n","        self.fc2 = nn.Linear(d_ff, d_model)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        return self.fc2(self.relu(self.fc1(x)))"],"metadata":{"id":"IlZr1vV6koI7","executionInfo":{"status":"ok","timestamp":1719149886009,"user_tz":-420,"elapsed":47,"user":{"displayName":"Vietnamese History Project","userId":"05323965769577706583"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, max_seq_length):\n","        super(PositionalEncoding, self).__init__()\n","\n","        pe = torch.zeros(max_seq_length, d_model)\n","        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n","\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","\n","        self.register_buffer('pe', pe.unsqueeze(0))\n","\n","    def forward(self, x):\n","        return x + self.pe[:, :x.size(1)]"],"metadata":{"id":"kbQSKlNEkqE3","executionInfo":{"status":"ok","timestamp":1719149886010,"user_tz":-420,"elapsed":46,"user":{"displayName":"Vietnamese History Project","userId":"05323965769577706583"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["class EncoderLayer(nn.Module):\n","    def __init__(self, d_model, n_head, d_ff, dropout):\n","        super(EncoderLayer, self).__init__()\n","        self.self_attn = MultiHeadAttention(d_model, n_head)\n","        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, mask):\n","        attn_output = self.self_attn(x, x, x, mask)\n","        x = self.norm1(x + self.dropout(attn_output))\n","        ff_output = self.feed_forward(x)\n","        x = self.norm2(x + self.dropout(ff_output))\n","        return x"],"metadata":{"id":"Y5QTXaVGkrcU","executionInfo":{"status":"ok","timestamp":1719149886010,"user_tz":-420,"elapsed":43,"user":{"displayName":"Vietnamese History Project","userId":"05323965769577706583"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["class TransformerEncoder(nn.Module):\n","    def __init__(self, vocab_size, d_model, n_head, num_layers, d_ff, max_seq_length, dropout):\n","        super(TransformerEncoder, self).__init__()\n","        self.vocab_size = vocab_size\n","        self.d_model = d_model\n","        self.n_head = n_head\n","        self.num_layers = num_layers\n","        self.d_ff = d_ff\n","        self.max_seq_length = max_seq_length\n","        self.dropout = nn.Dropout(dropout)\n","\n","        self.embedding = nn.Embedding(vocab_size, d_model)\n","        self.encoder = nn.ModuleList([EncoderLayer(d_model, n_head, d_ff, dropout) for _ in range(num_layers)])\n","\n","        self.positional_embedding = PositionalEncoding(d_model, max_seq_length)\n","\n","    def masking(self, x):\n","        x_mask = (x != tokenizer.pad_token_id).unsqueeze(1).unsqueeze(2).to(x.device)\n","        return x_mask\n","\n","    def forward(self, x):\n","        x_mask = self.masking(x)\n","\n","        x = self.embedding(x) * math.sqrt(self.d_model)\n","        x = self.dropout(self.positional_embedding(x))\n","\n","        for layer in self.encoder:\n","          x = layer(x, x_mask)\n","\n","        x = x.reshape(x.shape[0], -1)\n","\n","        return x\n","\n","x = torch.randint(size=(32, 10), low=0, high=1000)\n","\n","net = TransformerEncoder(vocab_size=1000, d_model=512, n_head=8, num_layers=4, d_ff=2048, max_seq_length=10, dropout=0.1)\n","\n","print(net(x).shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x3PH5sVzkxZy","executionInfo":{"status":"ok","timestamp":1719150286316,"user_tz":-420,"elapsed":889,"user":{"displayName":"Vietnamese History Project","userId":"05323965769577706583"}},"outputId":"e351cdaf-21e3-4ec1-a32d-bca83bfa21f6"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 5120])\n"]}]},{"cell_type":"code","source":["class TransformerEncoderClassification(nn.Module):\n","    def __init__(self, vocab_size=1000, d_model=512, n_head=8, num_layers=4, d_ff=2048, max_seq_length=64, dropout=0.1, num_classes=2):\n","        super(TransformerEncoderClassification, self).__init__()\n","        self.transformers_encoder = TransformerEncoder(vocab_size, d_model, n_head, num_layers, d_ff, max_seq_length, dropout)\n","        self.fc1 = nn.Linear(max_seq_length * d_model, d_model)\n","        self.fc2 = nn.Linear(d_model, 128)\n","        self.fc3 = nn.Linear(128, num_classes)\n","\n","    def forward(self, x):\n","        x = self.transformers_encoder(x)\n","\n","        print(x.shape)\n","\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","x =  torch.randint(size=(32, 10), low=1, high=100)\n","net = TransformerEncoderClassification(vocab_size=1000, d_model=512, n_head=8, num_layers=4, d_ff=2048, max_seq_length=10, dropout=0.1, num_classes=2)\n","a = net(x)\n","print(a.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bt30qd7strU0","executionInfo":{"status":"ok","timestamp":1719150277701,"user_tz":-420,"elapsed":1480,"user":{"displayName":"Vietnamese History Project","userId":"05323965769577706583"}},"outputId":"bdf62ca7-7b1c-4d21-f712-899e578721d5"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 5120])\n","torch.Size([32, 2])\n"]}]},{"cell_type":"markdown","metadata":{"id":"p3f2AD5ypofQ"},"source":["# Train"]},{"cell_type":"markdown","metadata":{"id":"tX5ZQ0o4pre_"},"source":["## Initialize, load, save model"]},{"cell_type":"code","execution_count":65,"metadata":{"id":"HLoUNhhfpxdR","executionInfo":{"status":"ok","timestamp":1719152688610,"user_tz":-420,"elapsed":7,"user":{"displayName":"Vietnamese History Project","userId":"05323965769577706583"}}},"outputs":[],"source":["def init_model():\n","    model = TransformerEncoderClassification(vocab_size=vocab_size,\n","                                             d_model=d_model,\n","                                             n_head=n_head,\n","                                             num_layers=num_layer,\n","                                             d_ff=d_ff,\n","                                             max_seq_length=max_token_length,\n","                                             dropout=dropout,\n","                                             num_classes=num_classes).to(device=device)\n","\n","    criterion = nn.CrossEntropyLoss().to(device=device)\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n","\n","    return model, criterion, optimizer\n","\n","def save_model(model, optimizer, epoch, path):\n","    torch.save({\n","        'epoch': epoch,\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","    }, path)\n","\n","def load(model, optimizer, path):\n","    checkpoint = torch.load(path, map_location=torch.device(device))\n","\n","    print(type(checkpoint[\"model_state_dict\"]))\n","\n","    model.load_state_dict(checkpoint[\"model_state_dict\"])\n","    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n","    epoch = checkpoint[\"epoch\"]\n","\n","    return model, optimizer, epoch"]},{"cell_type":"markdown","metadata":{"id":"jK53gFFSpvx9"},"source":["## Actual training loop"]},{"cell_type":"code","execution_count":69,"metadata":{"id":"7digBqomXXNR","executionInfo":{"status":"ok","timestamp":1719153196316,"user_tz":-420,"elapsed":844,"user":{"displayName":"Vietnamese History Project","userId":"05323965769577706583"}}},"outputs":[],"source":["def summary(loader, model, criterion):\n","    num_correct = 0\n","    num_samples = 0\n","    total_loss = 0\n","    loss_epoch = 0\n","    loss_avg = 0\n","\n","    model.eval()\n","\n","    acc = 0\n","\n","    with torch.no_grad():\n","        for index, (data, label) in enumerate(loader):\n","            data = data.to(device=device)\n","            label = label.to(device=device)\n","\n","            prob = model(data)\n","\n","            pred = torch.argmax(prob, dim=1)\n","\n","            current_correct = (pred == label).sum()\n","            current_size = pred.shape[0]\n","\n","            num_correct += current_correct\n","            num_samples += current_size\n","\n","            #print(data.shape)\n","            #print(label.shape)\n","            #print(pred.shape)\n","\n","            loss = criterion(prob, label)\n","\n","            loss_epoch += loss.item()\n","\n","        acc = float(num_correct)/float(num_samples) * 100.0\n","        loss_avg = float(loss_epoch)/float(len(loader))\n","    return acc, loss_avg"]},{"cell_type":"code","execution_count":70,"metadata":{"id":"LF811ZVdG79w","executionInfo":{"status":"ok","timestamp":1719153198008,"user_tz":-420,"elapsed":1250,"user":{"displayName":"Vietnamese History Project","userId":"05323965769577706583"}}},"outputs":[],"source":["def train(train_loader, val_loader, num_epochs, batch_print=40):\n","    train_acc_list = []\n","    train_loss_list = []\n","\n","    val_acc_list = []\n","    val_loss_list = []\n","\n","    cur_epoch = -1\n","\n","    model, criterion, optimizer = init_model()\n","\n","    numpy_final_result = [[] for _ in range(20)]\n","\n","    MODEL_SAVE_PATH = os.path.join(os.getcwd(), \"./eval/encoder_attention.pt\")\n","    JSON_SAVE_PATH = os.path.join(os.getcwd(), \"./eval/encoder_attention.json\")\n","\n","    if os.path.exists(MODEL_SAVE_PATH):\n","        model, optimizer, cur_epoch = load(model, optimizer, path=MODEL_SAVE_PATH)\n","\n","        #with open(NUMPY_SAVE_PATH, 'rb') as f:\n","        #    numpy_final_result = pickle.load(f)\n","\n","        ### LOAD MODEL ###\n","\n","    for epoch in range(num_epochs):\n","        if cur_epoch >= epoch:\n","            continue\n","\n","        correct_samples = 0\n","        total_samples = 0\n","\n","        loss_epoch = 0\n","\n","        print(\"----------------------------------------\")\n","\n","        model.train()\n","\n","        for batch_idx, (data, label) in enumerate(train_loader):\n","            # Data to CUDA if possible\n","            data = data.to(device=device)\n","            label = label.to(device=device)\n","\n","            print(data.shape)\n","            print(label.shape)\n","\n","            optimizer.zero_grad()\n","\n","            prob = model(data)\n","\n","            print(prob.shape)\n","            #prob.requires_grad=True\n","            prob.retain_grad()\n","\n","            pred = torch.argmax(prob, dim=1)\n","\n","            current_correct = (pred == label).sum()\n","            current_size = pred.shape[0]\n","\n","            correct_samples += current_correct\n","            total_samples += current_size\n","\n","            #print(data.shape)\n","            #print(label.shape)\n","            #print(pred.shape)\n","            #print(prob.shape)\n","\n","            loss = criterion(prob, label)\n","            loss.retain_grad()\n","            #loss.requires_grad=True\n","            loss.backward()\n","\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5)\n","            #optimizer.requires_grad=True\n","            optimizer.step()\n","\n","            loss_epoch += loss.item()\n","\n","            if batch_idx % batch_print == batch_print - 1:\n","                print(f\"Batch {batch_idx + 1}: Accuracy: {float(current_correct) / float(current_size) * 100.0}\")\n","                print(f\"Loss: {float(loss.item())}\")\n","                save_model(model=model, optimizer=optimizer, epoch=epoch, path=MODEL_SAVE_PATH)\n","\n","        # Validation\n","        val_acc, val_loss = summary(val_loader, model, criterion)\n","\n","        train_acc_list.append(float(correct_samples) / float(total_samples + 1e-12) * 100.0)\n","        train_loss_list.append(float(loss_epoch) / float(len(train_loader)))\n","\n","        val_acc_list.append(val_acc)\n","        val_loss_list.append(val_loss)\n","\n","        #for i in range(20):\n","        #    numpy_final_result[i].extend(final_result[i])\n","        #    print(f\"Prob for {i + 1}: min {np.min(numpy_final_result[i])}, max: {np.max(numpy_final_result[i])}\")\n","\n","        if epoch % 1 == 0:\n","            save_model(model=model, optimizer=optimizer, epoch=epoch, path=MODEL_SAVE_PATH)\n","\n","        cur_epoch = epoch\n","\n","        print(f\"Epoch {epoch + 1}:\")\n","\n","        print(f\"Train accuracy: {train_acc_list[-1]}%\")\n","        print(f\"Train loss: {train_loss_list[-1]}\")\n","\n","        print(f\"Val accuracy: {val_acc_list[-1]}%\")\n","        print(f\"Val loss: {val_loss_list[-1]}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mkuT2b8CLHeK","outputId":"e713f2fb-73af-4490-d66c-43e2a7c2defe"},"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","Batch 50: Accuracy: 56.25\n","Loss: 0.6831212639808655\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","Batch 100: Accuracy: 53.125\n","Loss: 0.6980240941047668\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","Batch 150: Accuracy: 53.125\n","Loss: 0.6787355542182922\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","Batch 200: Accuracy: 59.375\n","Loss: 0.6288442015647888\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","Batch 250: Accuracy: 78.125\n","Loss: 0.4865718185901642\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 65536])\n","torch.Size([32, 2])\n"]}],"source":["train(torch_train_loader, torch_val_loader, num_epochs=5, batch_print=50)"]}]}